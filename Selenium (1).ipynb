{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELENIUM ASSIGNMENT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM STATEMENT: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:  \n",
    "1.\tfirst get the webpage https://www.naukri.com/  \n",
    "2.\tEnter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.  \n",
    "3.\tThen click the search button.  \n",
    "4.\tThen scrape the data for the first 10 jobs results you get.  \n",
    "5.\tFinally create a dataframe of the scraped data.  \n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to web driver \n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Getting url/web page.\n",
    "\n",
    "url= \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding web element for search bar.\n",
    "# 2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field\n",
    "search_job= driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "# write on search bar 'Data Analyst'\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "# Finding element for job location and entering location as Banglore.\n",
    "search_loc= driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.clicking the search button using XPATH function.\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for saving data.\n",
    "job_title = []\n",
    "company_name = []\n",
    "experience = []\n",
    "days_of_posting = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having job titles.\n",
    "title_tag= driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Data Analyst - Informatica MDM',\n",
       " 'Assistant Vice President - MIS & Reporting ( Business Data Analyst)',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst/ MIS Reporting Analyst - Bangalore',\n",
       " 'Data analyst - Google Analytics',\n",
       " 'Senior/Regular Business Analyst / Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst @ Flipkart on Contract']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to job_title.\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "#Displaying top 10 search.\n",
    "job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'INTERTRUSTVITEOS CORPORATE AND FUND SERVICES PVT. LTD.',\n",
       " 'Myntra Designs Pvt. Ltd.',\n",
       " 'SA Tech Software (I) Pvt. Ltd.',\n",
       " 'PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd',\n",
       " 'H and M Hennes and Mauritz (P) Ltd.',\n",
       " 'Luxoft',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Flipkart Internet Private Limited']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting all tags having company name.\n",
    "company_tag= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "company_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '6-9 Yrs',\n",
       " '12-18 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-4 Yrs',\n",
       " '4-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-6 Yrs']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experience\n",
    "exp_tag= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in exp_tag:\n",
    "    experience.append(i.text)\n",
    "experience[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 DAYS AGO',\n",
       " '8 DAYS AGO',\n",
       " '12 DAYS AGO',\n",
       " '15 DAYS AGO',\n",
       " '10 DAYS AGO',\n",
       " '10 DAYS AGO',\n",
       " '13 DAYS AGO',\n",
       " '3 DAYS AGO',\n",
       " '3 DAYS AGO',\n",
       " '2 DAYS AGO']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Days of posting\n",
    "posting_day = driver.find_elements_by_xpath(\"//div[@class='type br2 fleft grey']\")\n",
    "for i in posting_day:\n",
    "    days_of_posting.append(i.text)\n",
    "days_of_posting[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.\n",
    "dataanalyst_jobs= pd.DataFrame({})\n",
    "dataanalyst_jobs['Title'] = job_title[:10]\n",
    "dataanalyst_jobs['Company name'] = company_name[:10]\n",
    "dataanalyst_jobs['Experince'] = experience[:10]\n",
    "dataanalyst_jobs['Days of Posting'] = days_of_posting[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experince</th>\n",
       "      <th>Days of Posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>11 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>8 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>12 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>15 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SA Tech Software (I) Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analyst - Google Analytics</td>\n",
       "      <td>H and M Hennes and Mauritz (P) Ltd.</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>13 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Regular Business Analyst / Data Analyst</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst @ Flipkart on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>2 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                     Data Analyst - Informatica MDM   \n",
       "2  Assistant Vice President - MIS & Reporting ( B...   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "6                    Data analyst - Google Analytics   \n",
       "7     Senior/Regular Business Analyst / Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9     Hiring For Data Analyst @ Flipkart on Contract   \n",
       "\n",
       "                                        Company name  Experince  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                Shell India Markets Private Limited    6-9 Yrs   \n",
       "2  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  12-18 Yrs   \n",
       "3                           Myntra Designs Pvt. Ltd.    3-6 Yrs   \n",
       "4                     SA Tech Software (I) Pvt. Ltd.    1-3 Yrs   \n",
       "5   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd    2-4 Yrs   \n",
       "6                H and M Hennes and Mauritz (P) Ltd.    4-7 Yrs   \n",
       "7                                             Luxoft    3-6 Yrs   \n",
       "8                  Flipkart Internet Private Limited    1-3 Yrs   \n",
       "9                  Flipkart Internet Private Limited    2-6 Yrs   \n",
       "\n",
       "  Days of Posting  \n",
       "0     11 DAYS AGO  \n",
       "1      8 DAYS AGO  \n",
       "2     12 DAYS AGO  \n",
       "3     15 DAYS AGO  \n",
       "4     10 DAYS AGO  \n",
       "5     10 DAYS AGO  \n",
       "6     13 DAYS AGO  \n",
       "7      3 DAYS AGO  \n",
       "8      3 DAYS AGO  \n",
       "9      2 DAYS AGO  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data\n",
    "dataanalyst_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM STATEMENT: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:  \n",
    "1.\tfirst get the webpage https://www.naukri.com/  \n",
    "2.\tEnter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.  \n",
    "3.\tThen click the search button.  \n",
    "4.\tThen scrape the data for the first 10 jobs results you get.  \n",
    "5.\tFinally create a dataframe of the scraped data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for saving data.\n",
    "job_title2 = []\n",
    "company_name2 = []\n",
    "experience2 = []\n",
    "days_of_posting2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to web driver \n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Getting url/web page.\n",
    "\n",
    "url= \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding web element for search bar.\n",
    "# 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field\n",
    "search_job= driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "# write on search bar 'Data Analyst'\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# Finding element for job location and entering location as Banglore.\n",
    "search_loc= driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.clicking the search button using XPATH function.\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having job titles.\n",
    "title_tag2= driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Senior Data Scientist, Modeling',\n",
       " 'Big Data - Data Scientist',\n",
       " 'Specialist I - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'SDE Lead Data Scientist-L3',\n",
       " 'Computational Design Lead Data Scientist-L3',\n",
       " 'Hiring For DATA Scientist - ON Contract Basis (3-6 Months)']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to job_title.\n",
    "for i in title_tag2:\n",
    "    job_title2.append(i.text)\n",
    "#Displaying top 10 search.\n",
    "job_title2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all tags having company name.\n",
    "company_tag2= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Nielsen',\n",
       " 'Xoriant Solutions Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Intel Technology India Pvt Ltd',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'Huawei Technologies India Pvt Ltd',\n",
       " 'GlobalEdx Learning and Technology Solution Pvt Ltd']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in company_tag2:\n",
    "    company_name2.append(i.text)\n",
    "company_name2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-3 Yrs',\n",
       " '4-7 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '6-10 Yrs',\n",
       " '5-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experience\n",
    "exp_tag2= driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in exp_tag2:\n",
    "    experience2.append(i.text)\n",
    "experience2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 DAYS AGO',\n",
       " '14 DAYS AGO',\n",
       " '7 DAYS AGO',\n",
       " '3 DAYS AGO',\n",
       " '9 DAYS AGO',\n",
       " '13 DAYS AGO',\n",
       " '8 DAYS AGO',\n",
       " '8 DAYS AGO',\n",
       " '3 DAYS AGO',\n",
       " '14 DAYS AGO']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Days of posting\n",
    "posting_day2 = driver.find_elements_by_xpath(\"//div[@class='type br2 fleft grey']\")\n",
    "for i in posting_day2:\n",
    "    days_of_posting2.append(i.text)\n",
    "days_of_posting2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.\n",
    "datascience_jobs= pd.DataFrame({})\n",
    "datascience_jobs['Title'] = job_title2[:10]\n",
    "datascience_jobs['Company name'] = company_name2[:10]\n",
    "datascience_jobs['Experince'] = experience2[:10]\n",
    "datascience_jobs['Days of Posting'] = days_of_posting2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experince</th>\n",
       "      <th>Days of Posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>11 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>14 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>7 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>13 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>8 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>8 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>14 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                    Senior Data Scientist, Modeling   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                Lead Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                         SDE Lead Data Scientist-L3   \n",
       "8        Computational Design Lead Data Scientist-L3   \n",
       "9  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "\n",
       "                                        Company name Experince Days of Posting  \n",
       "0                 Inflexion Analytix Private Limited   0-3 Yrs     11 DAYS AGO  \n",
       "1                                            Nielsen   3-7 Yrs     14 DAYS AGO  \n",
       "2                          Xoriant Solutions Pvt Ltd   1-3 Yrs      7 DAYS AGO  \n",
       "3                              Philips India Limited   4-7 Yrs      3 DAYS AGO  \n",
       "4                             IBM India Pvt. Limited   6-8 Yrs      9 DAYS AGO  \n",
       "5                     Intel Technology India Pvt Ltd  6-10 Yrs     13 DAYS AGO  \n",
       "6                             Oracle India Pvt. Ltd.  6-10 Yrs      8 DAYS AGO  \n",
       "7                  Huawei Technologies India Pvt Ltd   5-8 Yrs      8 DAYS AGO  \n",
       "8                  Huawei Technologies India Pvt Ltd   5-8 Yrs      3 DAYS AGO  \n",
       "9  GlobalEdx Learning and Technology Solution Pvt...   3-8 Yrs     14 DAYS AGO  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "datascience_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM STATEMENT: 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:  \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1.\tfirst get the webpage https://www.naukri.com/\n",
    "2.\tEnter “Data Scientist” in “Skill,Designations,Companies” field .  \n",
    "3.\tThen click the search button.\n",
    "4.\tThen apply the location filter and salary filter by checking the respective boxes\n",
    "4.\tThen scrape the data for the first 10 jobs results you get.\n",
    "5.\tFinally create a dataframe of the scraped data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for saving data.\n",
    "job_title3 = []\n",
    "company_name3 = []\n",
    "experience3 = []\n",
    "days_of_posting3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to web driver \n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Getting url/web page.\n",
    "\n",
    "url= \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding web element for search bar.\n",
    "# 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field\n",
    "search_job= driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "# write on search bar 'Data Scientist'\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# Finding element for job location and entering location as Delhi/NCR.\n",
    "search_loc= driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.clicking the search button using XPATH function.\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding element for salary and entering salary requirement as 3-6 lakhs.\n",
    "salary_filter= driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls to open each page.\n",
    "urls =[]\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='info fleft']/a\"):\n",
    "        urls.append(j.get_attribute('href'))\n",
    "    driver.find_element_by_xpath(\"//div[@class='fleft pages']/a\").click()\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from each url.\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\"):\n",
    "        job_title3.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "        company_name3.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\"):\n",
    "        experience3.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath(\"//div[@class='type br2 fleft grey']\"):\n",
    "        days_of_posting3.append(n.text)\n",
    "    driver.find_element_by_xpath(\"//div[@class='fleft pages']/a\").click()\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.\n",
    "ds_jobs_del= pd.DataFrame({})\n",
    "ds_jobs_del['Title'] = job_title3[:10]\n",
    "ds_jobs_del['Company name'] = company_name3[:10]\n",
    "ds_jobs_del['Experince'] = experience3[:10]\n",
    "ds_jobs_del['Days of Posting'] = days_of_posting3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experince</th>\n",
       "      <th>Days of Posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>11 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>7 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>15 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>13 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>13 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Blitz Jobs</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>2 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>21 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                   Business Analyst- Data Scientist   \n",
       "2  Data Scientist - High growth VC backed Influen...   \n",
       "3                                     Data Scientist   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6                             Data Scientist - Noida   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Company name Experince Days of Posting  \n",
       "0                 Inflexion Analytix Private Limited   0-3 Yrs     11 DAYS AGO  \n",
       "1                                              Wipro   2-5 Yrs      3 DAYS AGO  \n",
       "2                    Ravgins International Pvt. Ltd.   3-5 Yrs      7 DAYS AGO  \n",
       "3                                           Mobikwik   3-5 Yrs     15 DAYS AGO  \n",
       "4  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...   3-6 Yrs     13 DAYS AGO  \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...   3-6 Yrs     13 DAYS AGO  \n",
       "6     Optum Global Solutions (India) Private Limited   3-5 Yrs      9 DAYS AGO  \n",
       "7                                         Blitz Jobs   3-5 Yrs      2 DAYS AGO  \n",
       "8                             IBM India Pvt. Limited   4-9 Yrs     21 DAYS AGO  \n",
       "9                                     Country Veggie   1-3 Yrs    30+ DAYS AGO  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraped data\n",
    "ds_jobs_del"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM NO.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1.\tfirst get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2.\tEnter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3.\tThen click the search button. You will land up in the below page:\n",
    "4.\tThen scrape the data for the first 10 jobs results you get in the above shown page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to web driver \n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Getting url/web page.\n",
    "\n",
    "url= \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the company button to go to the search page.\n",
    "company_button= driver.find_element_by_xpath(\"//span[@class='sepafter pr-xxsm']/a\")\n",
    "company_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding web element for search bar.\n",
    "# 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field\n",
    "search_job= driver.find_element_by_id('sc.keyword')\n",
    "\n",
    "# write on search bar 'Data Scientist'\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# Finding element for job location and entering location as Delhi/NCR.\n",
    "search_loc= driver.find_element_by_id('sc.location')\n",
    "search_loc.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.clicking the search button using XPATH function.\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for saving data.\n",
    "job_title4 = []\n",
    "company_name4 = []\n",
    "days_of_posting4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having job titles.\n",
    "title_tag4= driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column pl-sm css-1d3xmk8 e1rrn5ka4']/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to save search to job_title.\n",
    "for i in title_tag4:\n",
    "    job_title4.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying top 10 search.\n",
    "job_title4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all tags having company name.\n",
    "company_tag4= driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in company_tag4:\n",
    "    company_name4.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ericsson',\n",
       " 'Mansha Solutions',\n",
       " 'Boston Consulting Group',\n",
       " 'Lantern Digital Services',\n",
       " 'Biz2Credit Inc',\n",
       " 'MasterCard',\n",
       " 'Priority Vendor',\n",
       " 'Sparkbpl',\n",
       " 'Skyjobs hr services',\n",
       " 'Gauge Data Solutions']"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all tags having days of posting.\n",
    "posting_tag4= driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in posting_tag4:\n",
    "    days_of_posting4.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d', '12d', '3d', '10d', '25d', '25d', '16d', '16d', '9d', '16d']"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_of_posting4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.\n",
    "ds_jobs_noi= pd.DataFrame({})\n",
    "ds_jobs_noi['Title'] = job_title4[:10]\n",
    "ds_jobs_noi['Company name'] = company_name4[:10]\n",
    "ds_jobs_noi['Days of Posting'] = days_of_posting4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Days of Posting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mansha Solutions</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>25d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>25d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>16d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sparkbpl</td>\n",
       "      <td>16d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Skyjobs hr services</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>16d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title              Company name Days of Posting\n",
       "0  Data Scientist                  Ericsson              3d\n",
       "1  Data Scientist          Mansha Solutions             12d\n",
       "2  Data Scientist   Boston Consulting Group              3d\n",
       "3  Data Scientist  Lantern Digital Services             10d\n",
       "4  Data Scientist            Biz2Credit Inc             25d\n",
       "5  Data Scientist                MasterCard             25d\n",
       "6  Data Scientist           Priority Vendor             16d\n",
       "7  Data Scientist                  Sparkbpl             16d\n",
       "8  Data Scientist       Skyjobs hr services              9d\n",
       "9  Data Scientist      Gauge Data Solutions             16d"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraped data\n",
    "ds_jobs_noi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM NO: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1.\tfirst get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2.\tEnter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3.\tClick the search button.\n",
    "4.\tAfter that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5.\tScrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.\tStore the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONNECTING TO WEBDRIVER\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting url\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding web element for search bar.\n",
    "# 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field\n",
    "search_job= driver.find_element_by_id('KeywordSearch')\n",
    "\n",
    "# write on search bar 'Data Scientist'\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "# Finding element for job location and entering location as Delhi/NCR.\n",
    "search_loc= driver.find_element_by_id('LocationSearch')\n",
    "search_loc.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.clicking the search button using XPATH function.\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datalists\n",
    "title5 =[]\n",
    "company5 =[]\n",
    "minsal =[]\n",
    "maxsal =[]\n",
    "avgsal =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having job titles.\n",
    "title_tag5= driver.find_elements_by_xpath(\"//div[@class='col-md-6']/div/div/p[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to job_title.\n",
    "for i in title_tag5:\n",
    "    title5.append(i.text)\n",
    "\n",
    "#Displaying top 10 search.\n",
    "title5[:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having company names.\n",
    "company_tag5= driver.find_elements_by_xpath(\"//div[@class='col-md-6']/div/div/p[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'IBM',\n",
       " 'Accenture',\n",
       " 'Ericsson-Worldwide',\n",
       " 'Delhivery',\n",
       " 'UnitedHealth Group',\n",
       " 'Valiance Solutions',\n",
       " 'ZS Associates',\n",
       " 'EXL Service',\n",
       " 'Optum Global Solutions']"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to company names.\n",
    "for i in company_tag5:\n",
    "    company5.append(i.text)\n",
    "\n",
    "#Displaying top 10 search.\n",
    "company5[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having avg sal.\n",
    "salaryavg= driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 6,14,306',\n",
       " '₹ 9,00,000',\n",
       " '₹ 11,46,533',\n",
       " '₹ 7,38,057',\n",
       " '₹ 12,39,781',\n",
       " '₹ 13,36,142',\n",
       " '₹ 8,15,192',\n",
       " '₹ 11,35,221',\n",
       " '₹ 11,44,243',\n",
       " '₹ 14,13,288']"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to job_title.\n",
    "for i in salaryavg:\n",
    "    avgsal.append(i.text)\n",
    "\n",
    "#Displaying top 10 search.\n",
    "avgsal[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having Minimum salary.\n",
    "salarymin= driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹343K',\n",
       " '₹586K',\n",
       " '₹577K',\n",
       " '₹355K',\n",
       " '₹450K',\n",
       " '₹1,069K',\n",
       " '₹502K',\n",
       " '₹202K',\n",
       " '₹575K',\n",
       " '₹1,014K']"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to minimum salary.\n",
    "for i in salarymin:\n",
    "    minsal.append(i.text)\n",
    "\n",
    "#Displaying top 10 search.\n",
    "minsal[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Scraping the data for the first 10 jobs results.\n",
    "# Extracting all tags having Minimum salary.\n",
    "salarymax= driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,250K',\n",
       " '₹2,730K',\n",
       " '₹2,213K',\n",
       " '₹1,613K',\n",
       " '₹11,622K',\n",
       " '₹1,520K',\n",
       " '₹1,465K',\n",
       " '₹1,809K',\n",
       " '₹1,520K',\n",
       " '₹2,149K']"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop to save search to maximum salary.\n",
    "for i in salarymax:\n",
    "    maxsal.append(i.text)\n",
    "\n",
    "#Displaying top 10 search.\n",
    "maxsal[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.\n",
    "ds_jobs_noi2= pd.DataFrame({})\n",
    "ds_jobs_noi2['Title'] = title5[:10]\n",
    "ds_jobs_noi2['Company name'] = company5[:10]\n",
    "ds_jobs_noi2['Average salary'] = avgsal[:10]\n",
    "ds_jobs_noi2['Minimum salary'] = minsal[:10]\n",
    "ds_jobs_noi2['Maximum salary'] = maxsal[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,14,306</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,250K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 9,00,000</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 14,13,288</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title               Company name Average salary Minimum salary  \\\n",
       "0  Data Scientist  Tata Consultancy Services     ₹ 6,14,306          ₹343K   \n",
       "1  Data Scientist                        IBM     ₹ 9,00,000          ₹586K   \n",
       "2  Data Scientist                  Accenture    ₹ 11,46,533          ₹577K   \n",
       "3  Data Scientist         Ericsson-Worldwide     ₹ 7,38,057          ₹355K   \n",
       "4  Data Scientist                  Delhivery    ₹ 12,39,781          ₹450K   \n",
       "5  Data Scientist         UnitedHealth Group    ₹ 13,36,142        ₹1,069K   \n",
       "6  Data Scientist         Valiance Solutions     ₹ 8,15,192          ₹502K   \n",
       "7  Data Scientist              ZS Associates    ₹ 11,35,221          ₹202K   \n",
       "8  Data Scientist                EXL Service    ₹ 11,44,243          ₹575K   \n",
       "9  Data Scientist     Optum Global Solutions    ₹ 14,13,288        ₹1,014K   \n",
       "\n",
       "  Maximum salary  \n",
       "0        ₹1,250K  \n",
       "1        ₹2,730K  \n",
       "2        ₹2,213K  \n",
       "3        ₹1,613K  \n",
       "4       ₹11,622K  \n",
       "5        ₹1,520K  \n",
       "6        ₹1,465K  \n",
       "7        ₹1,809K  \n",
       "8        ₹1,520K  \n",
       "9        ₹2,149K  "
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final data\n",
    "ds_jobs_noi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM NO:6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:  \n",
    "1.Brand  \n",
    "2.Product Description  \n",
    "3.Price  \n",
    "4.Discount %  \n",
    "The attributes which you have to scrape is ticked marked in the below image.  \n",
    "To scrape the data you have to go through following steps:  \n",
    "1.Go to flipkart webpage by url\thttps://www.flipkart.com/  \n",
    "2.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon.  \n",
    "3.after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.  \n",
    "4.after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.  \n",
    "5.Now scrape data from this page as usual.  \n",
    "6.repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONNECTING TO WEBDRIVER\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting url\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Entering sunglasses in search field\n",
    "search_bar= driver.find_element_by_name(\"q\")\n",
    "search_bar.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cicking search button\n",
    "search_but= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_but.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datalists\n",
    "brand =[]\n",
    "details =[]\n",
    "price =[]\n",
    "discount =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls to open each page.\n",
    "urls =[]\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\"):\n",
    "        urls.append(j.get_attribute('href'))\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from each url.\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class= '_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        details.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount.append(n.text)\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally create a dataframe of the scraped data.sunglass_data = pd.DataFrame({})\n",
    "sunglass_data['Brand']= brand[:100]\n",
    "sunglass_data['Product Details'] = details[:100]\n",
    "sunglass_data['Price']= price[:100]\n",
    "sunglass_data['Discount %']= discount[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Oval Sunglasses (56)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Polarized, UV Protection Wayfarer Sunglasses (52)</td>\n",
       "      <td>₹1,185</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Sports Sunglasses (Free Size)</td>\n",
       "      <td>₹292</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection Wayfarer, Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>elegante</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹574</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                    Product Details   Price  \\\n",
       "0     Silver Kartz                 UV Protection Oval Sunglasses (56)    ₹299   \n",
       "1       PHENOMENAL  UV Protection, Mirrored Retro Square Sunglasse...    ₹399   \n",
       "2   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...    ₹449   \n",
       "3           AISLIN  Polarized, UV Protection Wayfarer Sunglasses (52)  ₹1,185   \n",
       "4        ROYAL SON                   Mirrored Aviator Sunglasses (55)    ₹379   \n",
       "..             ...                                                ...     ...   \n",
       "95          GANSTA        UV Protection Sports Sunglasses (Free Size)    ₹292   \n",
       "96      PHENOMENAL   UV Protection Wrap-around Sunglasses (Free Size)    ₹319   \n",
       "97            hipe  UV Protection Wayfarer, Rectangular Sunglasses...    ₹319   \n",
       "98        elegante              UV Protection Aviator Sunglasses (58)    ₹499   \n",
       "99          AISLIN              UV Protection Aviator Sunglasses (57)    ₹574   \n",
       "\n",
       "   Discount %  \n",
       "0     75% off  \n",
       "1     80% off  \n",
       "2     77% off  \n",
       "3     72% off  \n",
       "4     74% off  \n",
       "..        ...  \n",
       "95    85% off  \n",
       "96    84% off  \n",
       "97    83% off  \n",
       "98    66% off  \n",
       "99    73% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Data\n",
    "sunglass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
